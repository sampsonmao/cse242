{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional probability Review\n",
    "\n",
    "If we remove 2 kings from a deck of 52 cards, there are 50 cards left over. Furthermore, the hearts and diamonds will have only 2 face cards each, giving them a total of 12 cards per suit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) $P(F) = \\frac{2}{50} = \\frac{1}{25}$\n",
    "\n",
    "b) $P(B) = \\frac{26}{50}=\\frac{13}{25}$\n",
    "\n",
    "c) $P(BF) =  \\frac{2}{50}=\\frac{1}{25}$\n",
    "\n",
    "d) $P(F|B) = \\frac{2}{26} = \\frac{1}{13}$\n",
    "\n",
    "e) $P(B|F) = 1$\n",
    "\n",
    "f) $P(BF) = P(F|B)P(B) = P(B|F)P(F)$\n",
    "\n",
    "> $\\quad \\frac{1}{25} = \\frac{1}{13} \\cdot \\frac{13}{25} = \\frac{1}{25}\\cdot1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) \n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(H|\\text{not a 2}) \n",
    "&= \\frac{P(\\text{not a 2|H})P(H)}{P(\\text{not a 2})} \\\\\n",
    "&= \\frac{[1-P(\\text{is a 2|H})]P(H)}{1-P(\\text{is a 2})}\\\\\n",
    "&= \\frac{\\left(1-\\frac{1}{12}\\right)\\left(\\frac{12}{50}\\right)}{1-\\frac{4}{50}} \\\\\n",
    "&= \\frac{1}{46}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) I will be using Scikit-learn to solve this linear regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Fitting the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(\n",
    "    [\n",
    "    [3, 9, 2, 19],\n",
    "    [6, 9, 1, 19],\n",
    "    [7, 7, 7, 10],\n",
    "    [8, 6, 4, 11],\n",
    "    [1, 0, 8, -3]\n",
    "    ]\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:3]\n",
    "y = data[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the hint mentions, the default setting for the `LinearRegression()` object is `fit_intercept=TRUE`, so it will calculate the intercept. This means we don't need a column of ones for the first column, and `X` is just the first 3 columns in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = linear_model.LinearRegression()\n",
    "LR.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model estimates the coefficients $\\theta_1, \\theta_2, \\theta_3$ in thiat order to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.13429383,  1.84768377, -0.89658481])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the intercept $\\theta_0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.360802923546112"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these coefficients, we can see how the model performs with the root-mean-square error\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{N}\\sum_i (f(x^{(i)}) - y)^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1897092217331575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred = LR.predict(X)\n",
    "RMSE = np.sqrt(sum((data_pred-y)**2)/len(y))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the built-in library function to check, we get the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1897092217331575"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(y, data_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So on average our predictions are 0.19 from the actual value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) The model would predict the following label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.01804869])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X = np.array([[3, 3, 5]])\n",
    "new_pred = LR.predict(new_X)\n",
    "new_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) If the examples are re-ordered, including the labels, there would be no change in the $\\theta$ vector. This is because in the log-likelihood function, all of the data is added together (in the likelihood, they are multiplied). Order does not matter for these operations. I.e., the likelihood function is the same regardless of how we permute the rows. We are not changing the label assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Probability Review\n",
    "\n",
    "First, we have\n",
    "\n",
    "$$\n",
    "P(H) = \\lambda\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Obtaining the first head at the $(k+1)$th toss means that the $k$ tosses before it were tails.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(\\{T\\}_{i=1}^kH) &= P(T)^kP(H) & (\\text{Independent tosses})\\\\\n",
    "&= (1-\\lambda)^k \\lambda\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Here we are saying the number of tosses $K$ before the first heads is a random variable, so the expectation is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E(K) &= \\sum_{k \\in \\mathbb{Z}^+} kP(K=k) \\\\\n",
    "&= \\sum_{k=1}^\\infty k(1-\\lambda)^k\\lambda \\\\\n",
    "&= \\lambda\\frac{1-\\lambda}{[(1-\\lambda)-1]^2} & (\\text{Wolfram Alpha}) \\\\\n",
    "&= \\frac{1-\\lambda}{\\lambda}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Now the random variable is the number of heads $Y$. If we toss the coin one time, then it has a probability mass function (pmf) of\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=y) &= \\lambda^y(1-\\lambda)^{1-y} & y \\in \\{0,1\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "If we have $N$ independent tosses, then we have to multiply the probability of success $y$ times, and multiply the probability of failure the remaining $N-y$ times. Also, the order of heads does not matter when we just want the number of heads, so the pmf is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=y) &= {N \\choose y} \\lambda^y(1-\\lambda)^{N-y} & y \\in \\{0,1,2,...\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Thus, the expected value of the number of heads $Y$ is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E(Y) &= \\sum_y yP(Y=y) \\\\\n",
    "&= \\sum_{y=0}^\\infty  y{N \\choose y} \\lambda^y(1-\\lambda)^{N-y} \\\\\n",
    "&= \\sum_{y=0}^\\infty y\\frac{N!}{y!(N-y)!}\\lambda^y(1-\\lambda)^{N-y} \\\\\n",
    "&= \\sum_{y=0}^\\infty \\frac{N(N-1)!}{(y-1)!(N-y)!}\\lambda^y(1-\\lambda)^{N-y} \\\\\n",
    "&= N\\sum_{y=0}^\\infty {N-1 \\choose y-1}\\lambda^y(1-\\lambda)^{N-y} & (N-1) - (y-1) = N-y \\\\\n",
    "&= N\\lambda\\sum_{y=0}^\\infty {N-1 \\choose y-1}\\lambda^{y-1}(1-\\lambda)^{(N-1)-(y-1)} \\\\\n",
    "&= N\\lambda\n",
    "\\end{aligned}\n",
    "$$\n",
    "The last step comes from the fact that pmfs sum to 1 and the expression inside the sum was the pmf of an experiment with $N-1$ independent tosses with $y-1$ heads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Continuous Variable plus Bayesâ€™s Rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) If my assigned probability density of $x$ is $f(x) = (n+1)x^n$ for $x \\in (0,1]$, then my expected value is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E(X) &= \\int_{-\\infty}^\\infty xf(x) \\, dx \\\\\n",
    "&= \\int_0^1 x(n+1)x^n \\, dx \\\\\n",
    "&= \\frac{n+1}{n+2}x^{n+2} \\bigg\\rvert_0^1 \\\\\n",
    "&= \\frac{n+1}{n+2}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Denote the random variable $Y$ for whether I heard thunder or not. $y=0$ means that I did not hear thunder and $y=1$ means that I did. Then the pmf for the probability of hearing thunder is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Y=y|x) &= (1-x)^y x^{1-y} & y \\in \\{0,1\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Then by Bayes' rule,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(x|Y=y) &\\propto  P(Y=y|x)f(x)\\\\\n",
    "&\\propto (1-x)^y x^{1-y}(n+1)x^n \\\\\n",
    "&\\propto (1-x)^y x^{1-y+n}\n",
    "\\end{aligned}\n",
    "$$\n",
    "So if we did not hear thunder, i.e. $y=0$, then the posterior density is proportional to\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(x|y=0) &\\propto x^{n+1}  & x \\in (0,1]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The normalizing factor is a factor $c$ that when multiplied with the pdf, the pdf sums to 1 on its support set.\n",
    "\n",
    "$$\n",
    "\\int_{0}^1 cx^{n+1} \\,dx = c\\frac{x^{n+2}}{n+2}\\bigg\\rvert_{0}^1 = \\frac{c}{n+2} = 1 \\\\\n",
    "\\implies c = n+2\n",
    "$$\n",
    "So the posterior density is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(x|y=1) &= (n+2)x^{n+1} & x \\in (0,1]\n",
    "\\end{aligned}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Sampson Mao"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "title": "CSE 242 Homework 1"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
